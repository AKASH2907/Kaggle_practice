{"cells":[{"metadata":{},"cell_type":"markdown","source":"Titanic competition is a very good way to introduce exploratory data analysis and classification models. I'm gonna explore the data and make something with them and also work upon the input missing values. Feature engineering is an important part of machine learning process so I want to spend more time for this part. I'm gonna try I few models and tell you which work the best with train dataset from this competition. Please consider upvoting if this is useful to you :) This Kernel is been taken from Karolina Pacocha. I'm trying to incorporate different machine learning algos, K-fold validation, different classifiers and GridSearch CV approach to improve the score."},{"metadata":{},"cell_type":"markdown","source":"**Import the Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport numpy as np\nimport math \nimport xgboost as xgb\nnp.random.seed(2019)\nfrom scipy.stats import skew\nfrom scipy import stats\n\nimport statsmodels\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import Data**"},{"metadata":{},"cell_type":"markdown","source":"I'm adding here 'train' variable in order to check in the easiest way later which observations are from train and test dataset because I'm gonna join train and test datasets."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain = train.set_index(\"PassengerId\")\ntest = test.set_index(\"PassengerId\")\n\ntrain['train'] = 1\ntest['train'] = 0\ndata = pd.concat([train,test],axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Explore the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PassengerId** - the unique id of the row, it doesn't have any effect on Survived value.\n\n**Survived** - binary:\n* 1 -> Survived\n* 0 -> Not survived\n\n**Pclass** (Passenger Class) - economic status of the passenger, this variable has 3 values;\n* 1 -> Upper Class\n* 2 -> Middle Class\n* 3 -> Lower Class\n\n**Name**, **Sex** and **Age** - are self-explanatory.\n\n**SibSp** - the total number of the passengers' siblings and spouse.\n\n**Parch** - the total number of the passengers' parents and children.\n\n**Ticket** - the ticket number.\n\n**Fare** - the passenger fare.\n\n**Cabin** - the cabin number.\n\n**Embarked** is port of embarkation, 3 values:\n* C -> Cherbourg\n* Q -> Queenstown\n* S -> Southampton"},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix between numerical values:"},{"metadata":{"trusted":true},"cell_type":"code","source":" g = sns.heatmap(data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlations between numerical variables and Survived aren't so high but it doesn't mean that the other features are not useful."},{"metadata":{},"cell_type":"markdown","source":"Parch vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Parch\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = sns.FacetGrid(data, col='Survived')\nk = k.map(sns.distplot, \"Parch\", hist=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SibSp vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"SibSp\", \"Survived\"]][data.Survived.isnull()==False].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col='Survived')\ng = g.map(sns.distplot, \"SibSp\", hist=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fare vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col='Survived')\ng = g.map(sns.distplot, \"Fare\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col='Survived')\ng = g.map(sns.distplot, \"Age\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sex vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Sex\",\"Survived\"]].groupby('Sex').mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pclass vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(data, col='Survived', row='Pclass', size=2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embarked vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = sns.FacetGrid(data, row='Embarked', col='Survived', size=2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 263 missing ages, 1014 missing cabins. Age is very important variable, so it's worth spending time to imput them. If it comes to imputing cabins - it's too hard to do because dataset has only 1309 observations so 77% cabins are missing."},{"metadata":{},"cell_type":"markdown","source":"Missing values in Embarked and Fare variables are very easy to imput because we can use the most popular value or something like that.\n\nI'm gonna replace missing value in Fare with 0 and in Embarked with the most popular value ('S')."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Pclass').Fare.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Fare = data.Fare.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Embarked.value_counts())\ndata.Embarked = data.Embarked.fillna('S')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If it comes to Cabin variable, I'm gonna fill up NaN values with 'Unknown' and get first letter from every Cabin in dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Cabin = data.Cabin.fillna('Unknown')\ndata['Cabin'] = data['Cabin'].str[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the distribution of the cabins in individual passenger classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Pclass').Cabin.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Cabin 'Unknown' will be set to C for the first class, D for the second class and G for the third class. One observation with Cabin 'T' and first class I'll fix with C."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cabin'] = np.where((data.Pclass==1) & (data.Cabin=='U'),'C',\n                                            np.where((data.Pclass==2) & (data.Cabin=='U'),'D',\n                                                                        np.where((data.Pclass==3) & (data.Cabin=='U'),'G',\n                                                                                                    np.where(data.Cabin=='T','C',data.Cabin))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I'm gonna get title from each Name in dataset. This variable will be very useful and it can help to imput missing value in Age. People's titles can represent their age, earnings and life status and all these three properties can be associated with the possibility of survival on a ship."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(data['Title'], data['Sex'])\ndata = data.drop('Name',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I need to replace a few titles with 'other' values because these titles are not as popular and have a low frequency of occurrence in this dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's replace a few titles -> \"other\" and fix a few titles\ndata['Title'] = np.where((data.Title=='Capt') | (data.Title=='Countess') | (data.Title=='Don') | (data.Title=='Dona')\n                        | (data.Title=='Jonkheer') | (data.Title=='Lady') | (data.Title=='Sir') | (data.Title=='Major') | (data.Title=='Rev') | (data.Title=='Col'),'Other',data.Title)\n\ndata['Title'] = data['Title'].replace('Ms','Miss')\ndata['Title'] = data['Title'].replace('Mlle','Miss')\ndata['Title'] = data['Title'].replace('Mme','Mrs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check how the distribution of survival variable  depending on the title."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\nfacet = sns.FacetGrid(data = data, hue = \"Title\", legend_out=True, size = 4.5)\nfacet = facet.map(sns.kdeplot, \"Age\")\nfacet.add_legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People with 'Master' have the highest survival rate. Maybe because people with the master are mainly boys under 13 years old."},{"metadata":{},"cell_type":"markdown","source":"Let's see distributions on box plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data = data, x = \"Title\", y = \"Age\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(data, hue=\"Survived\",aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, data['Age'].max()))\nfacet.add_legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age has a very large impact on the survival rate, but when this variable has missing values - it is useless. I'm gonna impute the missing values using the average age values in particular groups due to the titles."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Title').Age.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Age'] = np.where((data.Age.isnull()) & (data.Title=='Master'),5,\n                        np.where((data.Age.isnull()) & (data.Title=='Miss'),22,\n                                 np.where((data.Age.isnull()) & (data.Title=='Mr'),32,\n                                          np.where((data.Age.isnull()) & (data.Title=='Mrs'),37,\n                                                  np.where((data.Age.isnull()) & (data.Title=='Other'),45,\n                                                           np.where((data.Age.isnull()) & (data.Title=='Dr'),44,data.Age))))))                   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A few new variables:"},{"metadata":{},"cell_type":"markdown","source":"**Feature engineering**"},{"metadata":{},"cell_type":"markdown","source":"* FamilySize - number of family members, people travelling alone will have a value of 1\n* Women - it depends on Sex variable but I'm making it in binary way\n* Mother - women with Mrs title and at least 1 parch, women, children and mothers probably have a survival factor\n* Free - people who don't need to pay fare, these people could win tickets or something like that, they can have a similar survival rate\n* TypeOfTicket - prefixes of ticket, tickets with same prefixes may have a similar class and survival.\n\nIf it comes to TypeOfTicket variable I'm gonna also replace a few values of this variable with 'other' values, relying on the same as in the case of titles."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['FamilySize'] = data.SibSp + data.Parch + 1\ndata['Women'] = np.where(data.Sex=='female',1,0)\ndata['Mother'] = np.where((data.Title=='Mrs') & (data.Parch >0),1,0)\ndata['Free'] = np.where(data['Fare']==0, 1,0)\ndata = data.drop(['SibSp','Parch','Sex'],axis=1)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nTypeOfTicket = []\nfor i in range(len(data.Ticket)):\n    ticket = data.Ticket.iloc[i]\n    for c in string.punctuation:\n                ticket = ticket.replace(c,\"\")\n                splited_ticket = ticket.split(\" \")   \n    if len(splited_ticket) == 1:\n                TypeOfTicket.append('NO')\n    else: \n                TypeOfTicket.append(splited_ticket[0])\n            \ndata['TypeOfTicket'] = TypeOfTicket\n\ndata.TypeOfTicket.value_counts()\ndata['TypeOfTicket'] = np.where((data.TypeOfTicket!='NO') & (data.TypeOfTicket!='PC') & (data.TypeOfTicket!='CA') & \n                                (data.TypeOfTicket!='A5') & (data.TypeOfTicket!='SOTONOQ'),'other',data.TypeOfTicket)\ndata = data.drop('Ticket',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FamilySize vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"FamilySize\", \"Survived\"]][data.Survived.isnull()==False].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data, col='Survived')\ng = g.map(sns.distplot, 'FamilySize')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Title vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Title\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TypeOfTicket vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"TypeOfTicket\", \"Survived\"]][data.Survived.isnull()==False].groupby(['TypeOfTicket'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cabin vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Cabin\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Cabin'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mother vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Mother\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Mother'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Free vs Survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[\"Free\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Free'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm cutting Age variable to 5 equal intervals."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,12,24,45,60,data.Age.max()]\nlabels = ['Child', 'Young Adult', 'Adult','Older Adult','Senior']\ndata[\"Age\"] = pd.cut(data[\"Age\"], bins, labels = labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I create dummy variables for all variables with categories using the function get_dummies from pandas."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modeling**\n* Decision Tree Classifier\n* Random Forest Classifier\n* KNeighbors Classifier\n* SVM\n* Logistic Regression\n* Adaboost Classifier\n* XGB Classifier\n* Extra Trees Classifier\n* Gaussian Process Classifier"},{"metadata":{},"cell_type":"markdown","source":"To check how good each model is I'm gonna split dataset to train (70%) and test (30%) dataset (excluding missing values in Survived variable) and use Accuracy Score from sklearn.metrics. I set random_state to 2019 in order to compare the results between the models."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainX, testX, trainY, testY = train_test_split(data[data.Survived.isnull()==False].drop('Survived',axis=1),data.Survived[data.Survived.isnull()==False],test_size=0.30, random_state=2019)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm gonna to put result of each model in Data Frame 'Results'"},{"metadata":{"trusted":true},"cell_type":"code","source":"Results = pd.DataFrame({'Model': [],'Accuracy Score': []})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(max_depth=4)\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['DecisionTreeClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=2500, max_depth=4)\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['RandomForestClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNeighbors Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['KNeighborsClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel = SVC()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['SVC'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['LogisticRegression'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Adaboost Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['AdaBoostClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\nn_estimators = [100,140,145,150,160, 170,175,180,185];\ncv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\nlearning_r = [0.1,1,0.01,0.5]\n\nparameters = {'n_estimators':n_estimators,\n              'learning_rate':learning_r\n              \n        }\ngrid = GridSearchCV(AdaBoostClassifier(base_estimator= None, ## If None, then the base estimator is a decision tree.\n                                     ),\n                                 param_grid=parameters,\n                                 cv=cv,\n                                 n_jobs = -1)\ngrid.fit(trainX, trainY) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (grid.best_score_)\nprint (grid.best_params_)\nprint (grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adaBoost_grid = grid.best_estimator_\nadaBoost_grid.score(trainX, trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = adaBoost_grid.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['AdaBoostClassifier Grid Search CV'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGB Classifier**"},{"metadata":{},"cell_type":"markdown","source":"I put here some hyper-parameters tuning with n_estmators, max_depth and learning_rate parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\nmodel = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n                                max_depth=4, min_child_weight=0,\n                                gamma=0, subsample=0.7,\n                                colsample_bytree=0.7,\n                                scale_pos_weight=1, seed=27,\n                                reg_alpha=0.00006)\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['XGBClassifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extra Trees Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['Extra Trees Classifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gaussian Process Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.gaussian_process import GaussianProcessClassifier\nmodel = GaussianProcessClassifier()\nmodel.fit(trainX, trainY)\ny_pred = model.predict(testX)\nfrom sklearn.metrics import accuracy_score\nres = pd.DataFrame({\"Model\":['Gaussian Process Classifier'],\n                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\nResults = Results.append(res)\nprint(accuracy_score(y_pred,testY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How we see - XGB Classifier gives the best results. This model helps me to get 0.81339 on competition test dataset and it gives me place in 6% best results on Leaderboard."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import train_test_split\ntrainX = data[data.Survived.isnull()==False].drop(['Survived','train'],axis=1)\ntrainY = data.Survived[data.Survived.isnull()==False]\ntestX = data[data.Survived.isnull()==True].drop(['Survived','train'],axis=1)\nmodel = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n                                max_depth=4, min_child_weight=0,\n                                gamma=0, subsample=0.7,\n                                colsample_bytree=0.7,\n                                scale_pos_weight=1, seed=27,\n                                reg_alpha=0.00006)\nmodel.fit(trainX, trainY)\ntest = data[data.train==0]\ntest['Survived'] = model.predict(testX).astype(int)\ntest = test.reset_index()\ntest[['PassengerId','Survived']].to_csv(\"submissionXGB.csv\",index=False)\nprint(\"done1\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}