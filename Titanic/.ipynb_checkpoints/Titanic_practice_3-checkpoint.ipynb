{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic competition is a very good way to introduce exploratory data analysis and classification models. I'm gonna explore the data and make something with them and also work upon the input missing values. Feature engineering is an important part of machine learning process so I want to spend more time for this part. I'm gonna try I few models and tell you which work the best with train dataset from this competition. Please consider upvoting if this is useful to you :) This Kernel is been taken from Karolina Pacocha. I'm trying to incorporate different machine learning algos, K-fold validation, different classifiers and GridSearch CV approach to improve the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import xgboost as xgb\n",
    "np.random.seed(2019)\n",
    "from scipy.stats import skew\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm adding here 'train' variable in order to check in the easiest way later which observations are from train and test dataset because I'm gonna join train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "train = train.set_index(\"PassengerId\")\n",
    "test = test.set_index(\"PassengerId\")\n",
    "\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "data = pd.concat([train,test],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PassengerId** - the unique id of the row, it doesn't have any effect on Survived value.\n",
    "\n",
    "**Survived** - binary:\n",
    "* 1 -> Survived\n",
    "* 0 -> Not survived\n",
    "\n",
    "**Pclass** (Passenger Class) - economic status of the passenger, this variable has 3 values;\n",
    "* 1 -> Upper Class\n",
    "* 2 -> Middle Class\n",
    "* 3 -> Lower Class\n",
    "\n",
    "**Name**, **Sex** and **Age** - are self-explanatory.\n",
    "\n",
    "**SibSp** - the total number of the passengers' siblings and spouse.\n",
    "\n",
    "**Parch** - the total number of the passengers' parents and children.\n",
    "\n",
    "**Ticket** - the ticket number.\n",
    "\n",
    "**Fare** - the passenger fare.\n",
    "\n",
    "**Cabin** - the cabin number.\n",
    "\n",
    "**Embarked** is port of embarkation, 3 values:\n",
    "* C -> Cherbourg\n",
    "* Q -> Queenstown\n",
    "* S -> Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix between numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " g = sns.heatmap(data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between numerical variables and Survived aren't so high but it doesn't mean that the other features are not useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parch vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Parch\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sns.FacetGrid(data, col='Survived')\n",
    "k = k.map(sns.distplot, \"Parch\", hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SibSp vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"SibSp\", \"Survived\"]][data.Survived.isnull()==False].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Survived')\n",
    "g = g.map(sns.distplot, \"SibSp\", hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Survived')\n",
    "g = g.map(sns.distplot, \"Fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Survived')\n",
    "g = g.map(sns.distplot, \"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Sex\",\"Survived\"]].groupby('Sex').mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(data, col='Survived', row='Pclass', size=2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(data, row='Embarked', col='Survived', size=2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 263 missing ages, 1014 missing cabins. Age is very important variable, so it's worth spending time to imput them. If it comes to imputing cabins - it's too hard to do because dataset has only 1309 observations so 77% cabins are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in Embarked and Fare variables are very easy to imput because we can use the most popular value or something like that.\n",
    "\n",
    "I'm gonna replace missing value in Fare with 0 and in Embarked with the most popular value ('S')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Pclass').Fare.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Fare = data.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.Embarked.value_counts())\n",
    "data.Embarked = data.Embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it comes to Cabin variable, I'm gonna fill up NaN values with 'Unknown' and get first letter from every Cabin in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Cabin = data.Cabin.fillna('Unknown')\n",
    "data['Cabin'] = data['Cabin'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the cabins in individual passenger classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Pclass').Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cabin 'Unknown' will be set to C for the first class, D for the second class and G for the third class. One observation with Cabin 'T' and first class I'll fix with C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin'] = np.where((data.Pclass==1) & (data.Cabin=='U'),'C',\n",
    "                                            np.where((data.Pclass==2) & (data.Cabin=='U'),'D',\n",
    "                                                                        np.where((data.Pclass==3) & (data.Cabin=='U'),'G',\n",
    "                                                                                                    np.where(data.Cabin=='T','C',data.Cabin))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm gonna get title from each Name in dataset. This variable will be very useful and it can help to imput missing value in Age. People's titles can represent their age, earnings and life status and all these three properties can be associated with the possibility of survival on a ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(data['Title'], data['Sex'])\n",
    "data = data.drop('Name',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to replace a few titles with 'other' values because these titles are not as popular and have a low frequency of occurrence in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's replace a few titles -> \"other\" and fix a few titles\n",
    "data['Title'] = np.where((data.Title=='Capt') | (data.Title=='Countess') | (data.Title=='Don') | (data.Title=='Dona')\n",
    "                        | (data.Title=='Jonkheer') | (data.Title=='Lady') | (data.Title=='Sir') | (data.Title=='Major') | (data.Title=='Rev') | (data.Title=='Col'),'Other',data.Title)\n",
    "\n",
    "data['Title'] = data['Title'].replace('Ms','Miss')\n",
    "data['Title'] = data['Title'].replace('Mlle','Miss')\n",
    "data['Title'] = data['Title'].replace('Mme','Mrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the distribution of survival variable  depending on the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "facet = sns.FacetGrid(data = data, hue = \"Title\", legend_out=True, size = 4.5)\n",
    "facet = facet.map(sns.kdeplot, \"Age\")\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People with 'Master' have the highest survival rate. Maybe because people with the master are mainly boys under 13 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see distributions on box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = data, x = \"Title\", y = \"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(data, hue=\"Survived\",aspect=3)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, data['Age'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age has a very large impact on the survival rate, but when this variable has missing values - it is useless. I'm gonna impute the missing values using the average age values in particular groups due to the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Title').Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = np.where((data.Age.isnull()) & (data.Title=='Master'),5,\n",
    "                        np.where((data.Age.isnull()) & (data.Title=='Miss'),22,\n",
    "                                 np.where((data.Age.isnull()) & (data.Title=='Mr'),32,\n",
    "                                          np.where((data.Age.isnull()) & (data.Title=='Mrs'),37,\n",
    "                                                  np.where((data.Age.isnull()) & (data.Title=='Other'),45,\n",
    "                                                           np.where((data.Age.isnull()) & (data.Title=='Dr'),44,data.Age))))))                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few new variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FamilySize - number of family members, people travelling alone will have a value of 1\n",
    "* Women - it depends on Sex variable but I'm making it in binary way\n",
    "* Mother - women with Mrs title and at least 1 parch, women, children and mothers probably have a survival factor\n",
    "* Free - people who don't need to pay fare, these people could win tickets or something like that, they can have a similar survival rate\n",
    "* TypeOfTicket - prefixes of ticket, tickets with same prefixes may have a similar class and survival.\n",
    "\n",
    "If it comes to TypeOfTicket variable I'm gonna also replace a few values of this variable with 'other' values, relying on the same as in the case of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FamilySize'] = data.SibSp + data.Parch + 1\n",
    "data['Women'] = np.where(data.Sex=='female',1,0)\n",
    "data['Mother'] = np.where((data.Title=='Mrs') & (data.Parch >0),1,0)\n",
    "data['Free'] = np.where(data['Fare']==0, 1,0)\n",
    "data = data.drop(['SibSp','Parch','Sex'],axis=1)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "TypeOfTicket = []\n",
    "for i in range(len(data.Ticket)):\n",
    "    ticket = data.Ticket.iloc[i]\n",
    "    for c in string.punctuation:\n",
    "                ticket = ticket.replace(c,\"\")\n",
    "                splited_ticket = ticket.split(\" \")   \n",
    "    if len(splited_ticket) == 1:\n",
    "                TypeOfTicket.append('NO')\n",
    "    else: \n",
    "                TypeOfTicket.append(splited_ticket[0])\n",
    "            \n",
    "data['TypeOfTicket'] = TypeOfTicket\n",
    "\n",
    "data.TypeOfTicket.value_counts()\n",
    "data['TypeOfTicket'] = np.where((data.TypeOfTicket!='NO') & (data.TypeOfTicket!='PC') & (data.TypeOfTicket!='CA') & \n",
    "                                (data.TypeOfTicket!='A5') & (data.TypeOfTicket!='SOTONOQ'),'other',data.TypeOfTicket)\n",
    "data = data.drop('Ticket',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FamilySize vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"FamilySize\", \"Survived\"]][data.Survived.isnull()==False].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Survived')\n",
    "g = g.map(sns.distplot, 'FamilySize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Title\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TypeOfTicket vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"TypeOfTicket\", \"Survived\"]][data.Survived.isnull()==False].groupby(['TypeOfTicket'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Cabin\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Cabin'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mother vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Mother\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Mother'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Free\", \"Survived\"]][data.Survived.isnull()==False].groupby(['Free'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm cutting Age variable to 5 equal intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,12,24,45,60,data.Age.max()]\n",
    "labels = ['Child', 'Young Adult', 'Adult','Older Adult','Senior']\n",
    "data[\"Age\"] = pd.cut(data[\"Age\"], bins, labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create dummy variables for all variables with categories using the function get_dummies from pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**\n",
    "* Decision Tree Classifier\n",
    "* Random Forest Classifier\n",
    "* KNeighbors Classifier\n",
    "* SVM\n",
    "* Logistic Regression\n",
    "* Adaboost Classifier\n",
    "* XGB Classifier\n",
    "* Extra Trees Classifier\n",
    "* Gaussian Process Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check how good each model is I'm gonna split dataset to train (70%) and test (30%) dataset (excluding missing values in Survived variable) and use Accuracy Score from sklearn.metrics. I set random_state to 2019 in order to compare the results between the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(data[data.Survived.isnull()==False].drop('Survived',axis=1),data.Survived[data.Survived.isnull()==False],test_size=0.30, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna to put result of each model in Data Frame 'Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame({'Model': [],'Accuracy Score': []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['DecisionTreeClassifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=2500, max_depth=4)\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['RandomForestClassifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNeighbors Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['KNeighborsClassifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['SVC'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['LogisticRegression'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaboost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['AdaBoostClassifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "n_estimators = [100,140,145,150,160, 170,175,180,185];\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\n",
    "learning_r = [0.1,1,0.01,0.5]\n",
    "\n",
    "parameters = {'n_estimators':n_estimators,\n",
    "              'learning_rate':learning_r\n",
    "              \n",
    "        }\n",
    "grid = GridSearchCV(AdaBoostClassifier(base_estimator= None, ## If None, then the base estimator is a decision tree.\n",
    "                                     ),\n",
    "                                 param_grid=parameters,\n",
    "                                 cv=cv,\n",
    "                                 n_jobs = -1)\n",
    "grid.fit(trainX, trainY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoost_grid = grid.best_estimator_\n",
    "adaBoost_grid.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaBoost_grid.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['AdaBoostClassifier Grid Search CV'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I put here some hyper-parameters tuning with n_estmators, max_depth and learning_rate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "model = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n",
    "                                max_depth=4, min_child_weight=0,\n",
    "                                gamma=0, subsample=0.7,\n",
    "                                colsample_bytree=0.7,\n",
    "                                scale_pos_weight=1, seed=27,\n",
    "                                reg_alpha=0.00006)\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['XGBClassifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Trees Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['Extra Trees Classifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Process Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "model = GaussianProcessClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "y_pred = model.predict(testX)\n",
    "from sklearn.metrics import accuracy_score\n",
    "res = pd.DataFrame({\"Model\":['Gaussian Process Classifier'],\n",
    "                    \"Accuracy Score\": [accuracy_score(y_pred,testY)]})\n",
    "Results = Results.append(res)\n",
    "print(accuracy_score(y_pred,testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we see - XGB Classifier gives the best results. This model helps me to get 0.81339 on competition test dataset and it gives me place in 6% best results on Leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX = data[data.Survived.isnull()==False].drop(['Survived','train'],axis=1)\n",
    "trainY = data.Survived[data.Survived.isnull()==False]\n",
    "testX = data[data.Survived.isnull()==True].drop(['Survived','train'],axis=1)\n",
    "model = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n",
    "                                max_depth=4, min_child_weight=0,\n",
    "                                gamma=0, subsample=0.7,\n",
    "                                colsample_bytree=0.7,\n",
    "                                scale_pos_weight=1, seed=27,\n",
    "                                reg_alpha=0.00006)\n",
    "model.fit(trainX, trainY)\n",
    "test = data[data.train==0]\n",
    "test['Survived'] = model.predict(testX).astype(int)\n",
    "test = test.reset_index()\n",
    "test[['PassengerId','Survived']].to_csv(\"submissionXGB.csv\",index=False)\n",
    "print(\"done1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
